{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce021815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "import boto3\n",
    "import io \n",
    "import sagemaker.amazon.common as smac \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e4e8931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.read_csv('insurance.csv')\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cbc7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = pd.get_dummies(data = insurance, drop_first = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6ca97b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_male  smoker_yes  region_northwest  \\\n",
       "0   19  27.900         0  16884.92400         0           1                 0   \n",
       "1   18  33.770         1   1725.55230         1           0                 0   \n",
       "2   28  33.000         3   4449.46200         1           0                 0   \n",
       "3   33  22.705         0  21984.47061         1           0                 1   \n",
       "4   32  28.880         0   3866.85520         1           0                 1   \n",
       "\n",
       "   region_southeast  region_southwest  \n",
       "0                 0                 1  \n",
       "1                 1                 0  \n",
       "2                 1                 0  \n",
       "3                 0                 0  \n",
       "4                 0                 0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53c84dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(ins.drop(columns = ['charges']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "558fc2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_new).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0c1c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=ins['charges']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9ff308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_new).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4538b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57c60857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfa1c317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3707464 , -1.9133159 ,  1.5809257 , -1.0105187 , -0.5074631 ,\n",
       "       -0.5664179 , -0.61132365, -0.5664179 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ca35e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::051677741640:role/service-role/AmazonSageMaker-ExecutionRole-20211229T211710\n"
     ]
    }
   ],
   "source": [
    "#Create a SageMaker session\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = \"ml-sagemaker-gwu\"\n",
    "\n",
    "#Access SageMaker role created prior to session\n",
    "#Need to pass role to training job\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb7327a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://ml-sagemaker-gwu/medical_data/train/linear-train-data\n",
      "uploaded training data location: s3://ml-sagemaker-gwu/medical_data/test/linear-test-data\n",
      "Training artifacts will be uploaded to: s3://ml-sagemaker-gwu/medical_data/output\n"
     ]
    }
   ],
   "source": [
    "#Need to convert dataset to RecordIO format for Linear Learner to understand\n",
    "\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0) \n",
    "\n",
    "###Uploading training data\n",
    "#Filename for training data we are uploading to S3 \n",
    "key = 'linear-train-data'\n",
    "prefix = 'medical_data'\n",
    "#Upload training data to S3\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))\n",
    "\n",
    "###Uploading test data\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_test, y_test)\n",
    "buf.seek(0)\n",
    "\n",
    "#Sub-folder for test data\n",
    "key = 'linear-test-data'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_test_data))\n",
    "\n",
    "###Model Artifacts\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "985ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "container = image_uris.retrieve('linear-learner', boto3.Session().region_name)\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.c4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95a82f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.set_hyperparameters(feature_dim = 8,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 20,\n",
    "                           epochs = 5,\n",
    "                           num_models = 10,\n",
    "                           loss = 'absolute_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2baba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-03 00:38:56 Starting - Starting the training job...\n",
      "2022-01-03 00:38:58 Starting - Launching requested ML instancesProfilerReport-1641170336: InProgress\n",
      "...\n",
      "2022-01-03 00:39:53 Starting - Preparing the instances for training.........\n",
      "2022-01-03 00:41:21 Downloading - Downloading input data...\n",
      "2022-01-03 00:41:53 Training - Downloading the training image...\n",
      "2022-01-03 00:42:25 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'loss': 'absolute_loss', 'feature_dim': '8', 'num_models': '10', 'predictor_type': 'regressor', 'epochs': '5', 'mini_batch_size': '20'}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Final configuration: {'mini_batch_size': '20', 'epochs': '5', 'feature_dim': '8', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '10', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 WARNING 139680974665536] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Using default worker.\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:19.398] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 14, \"num_examples\": 1, \"num_bytes\": 1520}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Create Store: local\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:19.763] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 363, \"num_examples\": 54, \"num_bytes\": 81320}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f09a2a01750>\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Scaling model computed with parameters:\n",
      " {'stdev_label': \u001b[0m\n",
      "\u001b[34m[12109.028]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[0.9932665  1.0094569  1.0211405  1.0000526  0.9998801  0.99403304\n",
      " 1.0039036  1.0110084 ]\u001b[0m\n",
      "\u001b[34m<NDArray 8 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[34m[13249.321]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[-0.0033214   0.00440821  0.01987494 -0.00857703 -0.00016425 -0.00984202\n",
      "  0.00769385  0.01875673]\u001b[0m\n",
      "\u001b[34m<NDArray 8 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:19 INFO 139680974665536] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170539.8365545, \"EndTime\": 1641170539.8366182, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1090.0, \"count\": 1, \"min\": 1090, \"max\": 1090}, \"Total Batches Seen\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Max Records Seen Between Resets\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Max Batches Seen Between Resets\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:20.180] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 342, \"num_examples\": 54, \"num_bytes\": 81320}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.180078, \"EndTime\": 1641170540.180148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5734555140981135, \"count\": 1, \"min\": 0.5734555140981135, \"max\": 0.5734555140981135}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1802418, \"EndTime\": 1641170540.1802633, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5891032119966902, \"count\": 1, \"min\": 0.5891032119966902, \"max\": 0.5891032119966902}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1803157, \"EndTime\": 1641170540.1803317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5328401108957687, \"count\": 1, \"min\": 0.5328401108957687, \"max\": 0.5328401108957687}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1803806, \"EndTime\": 1641170540.1803977, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6102985566517092, \"count\": 1, \"min\": 0.6102985566517092, \"max\": 0.6102985566517092}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1804476, \"EndTime\": 1641170540.180464, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4916824043921705, \"count\": 1, \"min\": 0.4916824043921705, \"max\": 0.4916824043921705}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1805208, \"EndTime\": 1641170540.180537, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4588948996561878, \"count\": 1, \"min\": 0.4588948996561878, \"max\": 0.4588948996561878}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1805973, \"EndTime\": 1641170540.1806147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.49216964199857893, \"count\": 1, \"min\": 0.49216964199857893, \"max\": 0.49216964199857893}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1806703, \"EndTime\": 1641170540.1806877, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.47778415455008455, \"count\": 1, \"min\": 0.47778415455008455, \"max\": 0.47778415455008455}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1807399, \"EndTime\": 1641170540.1807573, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6217104034603766, \"count\": 1, \"min\": 0.6217104034603766, \"max\": 0.6217104034603766}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1808202, \"EndTime\": 1641170540.1808364, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5424836622094208, \"count\": 1, \"min\": 0.5424836622094208, \"max\": 0.5424836622094208}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #quality_metric: host=algo-1, epoch=0, train absolute_loss_objective <loss>=0.5734555140981135\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=absolute_loss_objective, value=0.4588948996561878\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Saved checkpoint to \"/tmp/tmpnkmji6qt/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170539.836988, \"EndTime\": 1641170540.192586, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2160.0, \"count\": 1, \"min\": 2160, \"max\": 2160}, \"Total Batches Seen\": {\"sum\": 109.0, \"count\": 1, \"min\": 109, \"max\": 109}, \"Max Records Seen Between Resets\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Max Batches Seen Between Resets\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Number of Batches Since Last Reset\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #throughput_metric: host=algo-1, train throughput=3007.864498474254 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:20.533] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 340, \"num_examples\": 54, \"num_bytes\": 81320}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5338254, \"EndTime\": 1641170540.5338783, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3810232010652434, \"count\": 1, \"min\": 0.3810232010652434, \"max\": 0.3810232010652434}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5339627, \"EndTime\": 1641170540.5339766, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3898308714605727, \"count\": 1, \"min\": 0.3898308714605727, \"max\": 0.3898308714605727}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5340152, \"EndTime\": 1641170540.5340576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36776857286129355, \"count\": 1, \"min\": 0.36776857286129355, \"max\": 0.36776857286129355}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5341184, \"EndTime\": 1641170540.534135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41055443725495966, \"count\": 1, \"min\": 0.41055443725495966, \"max\": 0.41055443725495966}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.534189, \"EndTime\": 1641170540.534205, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.352967130013232, \"count\": 1, \"min\": 0.352967130013232, \"max\": 0.352967130013232}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5342581, \"EndTime\": 1641170540.5342736, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.38415978112310734, \"count\": 1, \"min\": 0.38415978112310734, \"max\": 0.38415978112310734}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5343323, \"EndTime\": 1641170540.534349, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34508235926898023, \"count\": 1, \"min\": 0.34508235926898023, \"max\": 0.34508235926898023}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.534409, \"EndTime\": 1641170540.5344253, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.35040362623502624, \"count\": 1, \"min\": 0.35040362623502624, \"max\": 0.35040362623502624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5344772, \"EndTime\": 1641170540.5344944, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4232256569952335, \"count\": 1, \"min\": 0.4232256569952335, \"max\": 0.4232256569952335}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5345426, \"EndTime\": 1641170540.5345573, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3550117776078998, \"count\": 1, \"min\": 0.3550117776078998, \"max\": 0.3550117776078998}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #quality_metric: host=algo-1, epoch=1, train absolute_loss_objective <loss>=0.3810232010652434\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=absolute_loss_objective, value=0.34508235926898023\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Saved checkpoint to \"/tmp/tmptuqg7xw1/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.1928852, \"EndTime\": 1641170540.5422792, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3230.0, \"count\": 1, \"min\": 3230, \"max\": 3230}, \"Total Batches Seen\": {\"sum\": 163.0, \"count\": 1, \"min\": 163, \"max\": 163}, \"Max Records Seen Between Resets\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Max Batches Seen Between Resets\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Number of Batches Since Last Reset\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #throughput_metric: host=algo-1, train throughput=3061.312312969856 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:20.915] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 372, \"num_examples\": 54, \"num_bytes\": 81320}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9153636, \"EndTime\": 1641170540.9154205, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3153513120030457, \"count\": 1, \"min\": 0.3153513120030457, \"max\": 0.3153513120030457}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9155035, \"EndTime\": 1641170540.9155183, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.31508142385842663, \"count\": 1, \"min\": 0.31508142385842663, \"max\": 0.31508142385842663}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.915556, \"EndTime\": 1641170540.91557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3125473787199776, \"count\": 1, \"min\": 0.3125473787199776, \"max\": 0.3125473787199776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9156306, \"EndTime\": 1641170540.9156475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.32189573218237677, \"count\": 1, \"min\": 0.32189573218237677, \"max\": 0.32189573218237677}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9156978, \"EndTime\": 1641170540.9157143, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4236866941991842, \"count\": 1, \"min\": 0.4236866941991842, \"max\": 0.4236866941991842}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9157643, \"EndTime\": 1641170540.915781, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3891069104086678, \"count\": 1, \"min\": 0.3891069104086678, \"max\": 0.3891069104086678}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.915832, \"EndTime\": 1641170540.915849, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34468125014934897, \"count\": 1, \"min\": 0.34468125014934897, \"max\": 0.34468125014934897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9159002, \"EndTime\": 1641170540.9159172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36739881713435335, \"count\": 1, \"min\": 0.36739881713435335, \"max\": 0.36739881713435335}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.915967, \"EndTime\": 1641170540.9159825, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3319240900705446, \"count\": 1, \"min\": 0.3319240900705446, \"max\": 0.3319240900705446}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9160295, \"EndTime\": 1641170540.9160438, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3114840708813577, \"count\": 1, \"min\": 0.3114840708813577, \"max\": 0.3114840708813577}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #quality_metric: host=algo-1, epoch=2, train absolute_loss_objective <loss>=0.3153513120030457\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=absolute_loss_objective, value=0.3114840708813577\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] Saved checkpoint to \"/tmp/tmp18paxk60/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.5425532, \"EndTime\": 1641170540.923241, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4300.0, \"count\": 1, \"min\": 4300, \"max\": 4300}, \"Total Batches Seen\": {\"sum\": 217.0, \"count\": 1, \"min\": 217, \"max\": 217}, \"Max Records Seen Between Resets\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Max Batches Seen Between Resets\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Number of Batches Since Last Reset\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:20 INFO 139680974665536] #throughput_metric: host=algo-1, train throughput=2809.6803795903215 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:21.226] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 302, \"num_examples\": 54, \"num_bytes\": 81320}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2264607, \"EndTime\": 1641170541.226514, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3069718153971546, \"count\": 1, \"min\": 0.3069718153971546, \"max\": 0.3069718153971546}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2265954, \"EndTime\": 1641170541.2266092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.30649294763241175, \"count\": 1, \"min\": 0.30649294763241175, \"max\": 0.30649294763241175}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2266428, \"EndTime\": 1641170541.2266564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3061716192173508, \"count\": 1, \"min\": 0.3061716192173508, \"max\": 0.3061716192173508}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2266998, \"EndTime\": 1641170541.2267134, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.30814819425906775, \"count\": 1, \"min\": 0.30814819425906775, \"max\": 0.30814819425906775}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2267666, \"EndTime\": 1641170541.2267814, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.38977011284738217, \"count\": 1, \"min\": 0.38977011284738217, \"max\": 0.38977011284738217}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2268333, \"EndTime\": 1641170541.2268488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.40090870317423116, \"count\": 1, \"min\": 0.40090870317423116, \"max\": 0.40090870317423116}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2269008, \"EndTime\": 1641170541.2269168, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36765231681319904, \"count\": 1, \"min\": 0.36765231681319904, \"max\": 0.36765231681319904}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2269785, \"EndTime\": 1641170541.2269952, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36453012003088897, \"count\": 1, \"min\": 0.36453012003088897, \"max\": 0.36453012003088897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.227054, \"EndTime\": 1641170541.2270713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.30930716125470287, \"count\": 1, \"min\": 0.30930716125470287, \"max\": 0.30930716125470287}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.2271228, \"EndTime\": 1641170541.227138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.30608504088419786, \"count\": 1, \"min\": 0.30608504088419786, \"max\": 0.30608504088419786}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, epoch=3, train absolute_loss_objective <loss>=0.3069718153971546\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=absolute_loss_objective, value=0.30608504088419786\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Saved checkpoint to \"/tmp/tmpx1fc19kw/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170540.9235585, \"EndTime\": 1641170541.2345326, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5370.0, \"count\": 1, \"min\": 5370, \"max\": 5370}, \"Total Batches Seen\": {\"sum\": 271.0, \"count\": 1, \"min\": 271, \"max\": 271}, \"Max Records Seen Between Resets\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Max Batches Seen Between Resets\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Number of Batches Since Last Reset\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #throughput_metric: host=algo-1, train throughput=3439.1607289825906 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:21.611] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 376, \"num_examples\": 54, \"num_bytes\": 81320}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.611496, \"EndTime\": 1641170541.611556, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3055357834078231, \"count\": 1, \"min\": 0.3055357834078231, \"max\": 0.3055357834078231}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.6116533, \"EndTime\": 1641170541.611725, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.30434282748204355, \"count\": 1, \"min\": 0.30434282748204355, \"max\": 0.30434282748204355}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.6118228, \"EndTime\": 1641170541.611843, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3043943614329932, \"count\": 1, \"min\": 0.3043943614329932, \"max\": 0.3043943614329932}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.6119003, \"EndTime\": 1641170541.6119535, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3051894149690304, \"count\": 1, \"min\": 0.3051894149690304, \"max\": 0.3051894149690304}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.612039, \"EndTime\": 1641170541.6120582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3890946824595613, \"count\": 1, \"min\": 0.3890946824595613, \"max\": 0.3890946824595613}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.612108, \"EndTime\": 1641170541.6121242, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3754956065483813, \"count\": 1, \"min\": 0.3754956065483813, \"max\": 0.3754956065483813}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.6121745, \"EndTime\": 1641170541.6121907, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3657331995244296, \"count\": 1, \"min\": 0.3657331995244296, \"max\": 0.3657331995244296}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.6122339, \"EndTime\": 1641170541.612249, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3857727010295076, \"count\": 1, \"min\": 0.3857727010295076, \"max\": 0.3857727010295076}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.6122992, \"EndTime\": 1641170541.6123147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3074231444664721, \"count\": 1, \"min\": 0.3074231444664721, \"max\": 0.3074231444664721}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.6123648, \"EndTime\": 1641170541.6123803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.30421894473849603, \"count\": 1, \"min\": 0.30421894473849603, \"max\": 0.30421894473849603}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, epoch=4, train absolute_loss_objective <loss>=0.3055357834078231\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=absolute_loss_objective, value=0.30421894473849603\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Saved checkpoint to \"/tmp/tmpdpv4j5dj/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170541.234814, \"EndTime\": 1641170541.619745, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6440.0, \"count\": 1, \"min\": 6440, \"max\": 6440}, \"Total Batches Seen\": {\"sum\": 325.0, \"count\": 1, \"min\": 325, \"max\": 325}, \"Max Records Seen Between Resets\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Max Batches Seen Between Resets\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 1070.0, \"count\": 1, \"min\": 1070, \"max\": 1070}, \"Number of Batches Since Last Reset\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}}}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #throughput_metric: host=algo-1, train throughput=2778.7201024334126 records/second\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 WARNING 139680974665536] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 WARNING 139680974665536] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:21.620] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 0, \"num_examples\": 1, \"num_bytes\": 1520}\u001b[0m\n",
      "\u001b[34m[2022-01-03 00:42:21.713] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 90, \"num_examples\": 54, \"num_bytes\": 81320}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #train_score (algo-1) : ('absolute_loss_objective', 3663.2041691004674)\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #train_score (algo-1) : ('mse', 48490548.321495324)\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #train_score (algo-1) : ('absolute_loss', 3663.2041691004674)\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #train_score (algo-1) : ('rmse', 6963.515514558385)\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #train_score (algo-1) : ('r2', 0.6694000608864198)\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #train_score (algo-1) : ('mae', 3663.204191232842)\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, train absolute_loss_objective <loss>=3663.2041691004674\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, train mse <loss>=48490548.321495324\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, train absolute_loss <loss>=3663.2041691004674\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, train rmse <loss>=6963.515514558385\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, train r2 <loss>=0.6694000608864198\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] #quality_metric: host=algo-1, train mae <loss>=3663.204191232842\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.01, \"l1\": 0.0, \"lr_scheduler_step\": 100, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Saved checkpoint to \"/tmp/tmphina4l88/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/03/2022 00:42:21 INFO 139680974665536] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641170539.3833995, \"EndTime\": 1641170541.721057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 452.12841033935547, \"count\": 1, \"min\": 452.12841033935547, \"max\": 452.12841033935547}, \"epochs\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"check_early_stopping.time\": {\"sum\": 5.536079406738281, \"count\": 5, \"min\": 0.9698867797851562, \"max\": 1.1894702911376953}, \"update.time\": {\"sum\": 1763.9434337615967, \"count\": 5, \"min\": 308.17508697509766, \"max\": 382.1604251861572}, \"finalize.time\": {\"sum\": 97.48148918151855, \"count\": 1, \"min\": 97.48148918151855, \"max\": 97.48148918151855}, \"setuptime\": {\"sum\": 23.406267166137695, \"count\": 1, \"min\": 23.406267166137695, \"max\": 23.406267166137695}, \"totaltime\": {\"sum\": 2579.874277114868, \"count\": 1, \"min\": 2579.874277114868, \"max\": 2579.874277114868}}}\u001b[0m\n",
      "\n",
      "2022-01-03 00:42:53 Completed - Training job completed\n",
      "Training seconds: 71\n",
      "Billable seconds: 71\n"
     ]
    }
   ],
   "source": [
    "linear.fit({'train': s3_train_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7c32c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "linear_regressor = linear.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')\n",
    "\n",
    "#need to make sure data is in correct format for deployed model\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "linear_regressor.serializer = csv_serializer\n",
    "linear_regressor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a2f624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7faeb91bf7f0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = linear_regressor.predict(X_test)\n",
    "result #should be a JSON\n",
    "\n",
    "#Iterate the result JSON to get an NP array of all the predictions so we can compare to Y test\n",
    "predictions = np.array([res['score'] for res in result['predictions']])\n",
    "predictions #should now be an numpy array\n",
    "\n",
    "#Visualize how accurate predictions are relative to y_test\n",
    "plt.scatter(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "973f98e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7023.8777555925935"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "np.sqrt(metrics.mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e052627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker.Session().delete_endpoint(linear_regressor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c65ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
